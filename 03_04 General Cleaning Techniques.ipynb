{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Retention Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "sns.set()\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/BankChurners_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Cleaning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next important step when working with any dataset, is to perform any necessary cleaning steps. This includes (but is not limited to): 1) converting incorrect variable data types, 2) dropping or imputing missing (`NULL`) values, 3) finding and fixing erroneous values, and 4) handling outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A really good high level check to do at the start is to check for duplicates in the dataset. If there is a unique index you can check on like customer or advertiser IDs then that's the best variable to check uniques on by using the `nunique()` method. Else, you can use the `.drop_duplicates()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10127, 23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10127"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['CLIENTNUM'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10127, 23)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicates based on `CLIENTNUM`--good to go! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will look at the column names and see if we want to change column names or subset the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CLIENTNUM', 'Attrition_Flag', 'Customer_Age', 'Gender',\n",
       "       'Dependent_count', 'Education_Level', 'Marital_Status',\n",
       "       'Income_Category', 'Card_Category', 'Months_on_book',\n",
       "       'Total_Relationship_Count', 'Months_Inactive_12_mon',\n",
       "       'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal',\n",
       "       'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',\n",
       "       'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio',\n",
       "       'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n",
       "       'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will likely not need the naive bayes classifiers that they've created, so for simplicity, we will subset to remove them with the following code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['CLIENTNUM', 'Attrition_Flag', 'Customer_Age', 'Gender',\n",
    "       'Dependent_count', 'Education_Level', 'Marital_Status',\n",
    "       'Income_Category', 'Card_Category', 'Months_on_book',\n",
    "       'Total_Relationship_Count', 'Months_Inactive_12_mon',\n",
    "       'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal',\n",
    "       'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',\n",
    "       'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio',]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will take a look at datatypes. To check for datatypes, we will type `df.dtypes` to see how each variable has been read in. Main things to check here are dates and numbers that have been read in as string values and will need to be converted into their respective types in order to work with those variables as intended. Here we see that we have three different datatypes `int64`, `float64` and `object`. The `object` dtype is roughly analogous to str in native Python. You can reference the [user guide](https://pandas.pydata.org/docs/user_guide/basics.html#basics-dtypes) for pandas dtypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIENTNUM                     int64\n",
       "Attrition_Flag               object\n",
       "Customer_Age                  int64\n",
       "Gender                       object\n",
       "Dependent_count               int64\n",
       "Education_Level              object\n",
       "Marital_Status               object\n",
       "Income_Category              object\n",
       "Card_Category                object\n",
       "Months_on_book                int64\n",
       "Total_Relationship_Count      int64\n",
       "Months_Inactive_12_mon        int64\n",
       "Contacts_Count_12_mon         int64\n",
       "Credit_Limit                float64\n",
       "Total_Revolving_Bal           int64\n",
       "Avg_Open_To_Buy             float64\n",
       "Total_Amt_Chng_Q4_Q1        float64\n",
       "Total_Trans_Amt               int64\n",
       "Total_Trans_Ct                int64\n",
       "Total_Ct_Chng_Q4_Q1         float64\n",
       "Avg_Utilization_Ratio       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (main, Jan 18 2023, 00:26:41) [GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
